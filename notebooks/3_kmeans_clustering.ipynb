{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo 3: K-Means Clustering\n",
        "\n",
        "**Objetivo:** Segmentación de clientes de Telco en clusters\n",
        "\n",
        "**Algoritmo:** K-Means (k=3)\n",
        "\n",
        "**Dataset:** Telco Customer Churn (7,043 registros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. PREPROCESAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar estilo\n",
        "sns.set_style('darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Original:\n",
            "Dimensiones: (10, 21)\n",
            "Columnas: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n"
          ]
        }
      ],
      "source": [
        "# Cargar dataset\n",
        "df = pd.read_csv('../datasets/telco_churn.csv')\n",
        "print('Dataset Original:')\n",
        "print(f'Dimensiones: {df.shape}')\n",
        "print(f'Columnas: {df.columns.tolist()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset después de limpieza: (10, 21)\n",
            "Filas removidas: 0\n"
          ]
        }
      ],
      "source": [
        "# Limpieza\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df_clean = df.dropna()\n",
        "\n",
        "print(f'Dataset después de limpieza: {df_clean.shape}')\n",
        "print(f'Filas removidas: {df.shape[0] - df_clean.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables categóricas codificadas: 17\n",
            "Dataset codificado: (10, 21)\n"
          ]
        }
      ],
      "source": [
        "# Codificación de variables categóricas\n",
        "df_encoded = df_clean.copy()\n",
        "categorical_cols = df_encoded.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
        "\n",
        "print(f'Variables categóricas codificadas: {len(categorical_cols)}')\n",
        "print(f'Dataset codificado: {df_encoded.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features para clustering: (10, 21)\n",
            "\n",
            "Estadísticas básicas:\n",
            "       customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n",
            "count       10.00   10.00           10.0    10.00       10.00   10.00   \n",
            "mean         4.50    0.50            0.0     0.20        0.20   21.40   \n",
            "std          3.03    0.53            0.0     0.42        0.42   20.78   \n",
            "min          0.00    0.00            0.0     0.00        0.00    1.00   \n",
            "25%          2.25    0.00            0.0     0.00        0.00    3.50   \n",
            "50%          4.50    0.50            0.0     0.00        0.00   16.00   \n",
            "75%          6.75    1.00            0.0     0.00        0.00   32.50   \n",
            "max          9.00    1.00            0.0     1.00        1.00   62.00   \n",
            "\n",
            "       PhoneService  MultipleLines  InternetService  OnlineSecurity  ...  \\\n",
            "count         10.00          10.00            10.00           10.00  ...   \n",
            "mean           0.70           0.90             0.40            0.50  ...   \n",
            "std            0.48           0.88             0.52            0.53  ...   \n",
            "min            0.00           0.00             0.00            0.00  ...   \n",
            "25%            0.25           0.00             0.00            0.00  ...   \n",
            "50%            1.00           1.00             0.00            0.50  ...   \n",
            "75%            1.00           1.75             1.00            1.00  ...   \n",
            "max            1.00           2.00             1.00            1.00  ...   \n",
            "\n",
            "       DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
            "count             10.00        10.00        10.00            10.00     10.00   \n",
            "mean               0.40         0.20         0.30             0.20      0.30   \n",
            "std                0.52         0.42         0.48             0.42      0.48   \n",
            "min                0.00         0.00         0.00             0.00      0.00   \n",
            "25%                0.00         0.00         0.00             0.00      0.00   \n",
            "50%                0.00         0.00         0.00             0.00      0.00   \n",
            "75%                1.00         0.00         0.75             0.00      0.75   \n",
            "max                1.00         1.00         1.00             1.00      1.00   \n",
            "\n",
            "       PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges  Churn  \n",
            "count             10.00          10.00           10.00         10.00  10.00  \n",
            "mean               0.60           1.80           63.31       1362.57   0.40  \n",
            "std                0.52           1.14           27.14       1266.53   0.52  \n",
            "min                0.00           0.00           29.75         29.85   0.00  \n",
            "25%                0.00           1.25           45.19        189.21   0.00  \n",
            "50%                1.00           2.00           56.55       1330.62   0.00  \n",
            "75%                1.00           2.75           84.50       1934.43   1.00  \n",
            "max                1.00           3.00          104.80       3487.95   1.00  \n",
            "\n",
            "[8 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "# Usar todos los features para clustering\n",
        "X = df_encoded.copy()\n",
        "\n",
        "print(f'Features para clustering: {X.shape}')\n",
        "print(f'\\nEstadísticas básicas:')\n",
        "print(X.describe().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Datos normalizados\n",
            "Media: [1.11022302e-17 0.00000000e+00 0.00000000e+00] (primeros 3)\n",
            "Desv. Est.: [1. 1. 0.] (primeros 3)\n"
          ]
        }
      ],
      "source": [
        "# Normalización (CRÍTICA para K-Means)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print('✓ Datos normalizados')\n",
        "print(f'Media: {X_scaled.mean(axis=0)[:3]} (primeros 3)')\n",
        "print(f'Desv. Est.: {X_scaled.std(axis=0)[:3]} (primeros 3)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ENTRENAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Number of labels is 10. Valid values are 2 to n_samples - 1 (inclusive)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     kmeans_temp.fit(X_scaled)\n\u001b[32m      9\u001b[39m     inertias.append(kmeans_temp.inertia_)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     silhouette_scores.append(\u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmeans_temp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabels_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEvaluación de clusters (Elbow Method):\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, inertia, sil \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(K_range, inertias, silhouette_scores):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:138\u001b[39m, in \u001b[36msilhouette_score\u001b[39m\u001b[34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[39m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    137\u001b[39m         X, labels = X[indices], labels[indices]\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.mean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:296\u001b[39m, in \u001b[36msilhouette_samples\u001b[39m\u001b[34m(X, labels, metric, **kwds)\u001b[39m\n\u001b[32m    294\u001b[39m n_samples = \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[32m    295\u001b[39m label_freqs = np.bincount(labels)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m \u001b[43mcheck_number_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m kwds[\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m] = metric\n\u001b[32m    299\u001b[39m reduce_func = functools.partial(\n\u001b[32m    300\u001b[39m     _silhouette_reduce, labels=labels, label_freqs=label_freqs\n\u001b[32m    301\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:35\u001b[39m, in \u001b[36mcheck_number_of_labels\u001b[39m\u001b[34m(n_labels, n_samples)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m    Number of samples.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m1\u001b[39m < n_labels < n_samples:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m         % n_labels\n\u001b[32m     38\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: Number of labels is 10. Valid values are 2 to n_samples - 1 (inclusive)"
          ]
        }
      ],
      "source": [
        "# Método Elbow para encontrar k óptimo\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans_temp.fit(X_scaled)\n",
        "    inertias.append(kmeans_temp.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, kmeans_temp.labels_))\n",
        "\n",
        "print('Evaluación de clusters (Elbow Method):')\n",
        "for k, inertia, sil in zip(K_range, inertias, silhouette_scores):\n",
        "    print(f'k={k}: Inertia={inertia:.2f}, Silhouette={sil:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelo K-Means con k=3\n",
        "kmeans_model = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans_model.fit_predict(X_scaled)\n",
        "\n",
        "print('K-Means modelo entrenado con k=3')\n",
        "print(f'\\nCentros de clusters (primeras 3 features):')\n",
        "print(kmeans_model.cluster_centers_[:, :3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Añadir etiquetas al dataframe\n",
        "df_clustered = df_encoded.copy()\n",
        "df_clustered['Cluster'] = cluster_labels\n",
        "\n",
        "print('Clusters asignados al dataset')\n",
        "print(df_clustered.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. RESULTADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análisis de clusters\n",
        "print('DISTRIBUCIÓN DE CLUSTERS:')\n",
        "print('='*40)\n",
        "cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
        "for cluster, count in cluster_counts.items():\n",
        "    percentage = (count / len(cluster_labels)) * 100\n",
        "    print(f'Cluster {cluster}: {count:,} clientes ({percentage:.1f}%)')\n",
        "\n",
        "print(f'\\nTotal de clientes: {len(cluster_labels):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Características por cluster\n",
        "print('\\nCARACTERÍSTICAS PROMEDIO POR CLUSTER:')\n",
        "print('='*60)\n",
        "\n",
        "cluster_profiles = df_clustered.groupby('Cluster').mean()\n",
        "print(cluster_profiles.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análisis de Churn por cluster\n",
        "print('\\nTASA DE CHURN POR CLUSTER:')\n",
        "print('='*40)\n",
        "\n",
        "for cluster in range(3):\n",
        "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster]\n",
        "    churn_rate = (cluster_data['Churn'].sum() / len(cluster_data)) * 100\n",
        "    print(f'Cluster {cluster}: {churn_rate:.2f}% tasa de Churn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. MÉTRICAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular métricas de clustering\n",
        "silhouette = silhouette_score(X_scaled, cluster_labels)\n",
        "davies_bouldin = davies_bouldin_score(X_scaled, cluster_labels)\n",
        "calinski_harabasz = calinski_harabasz_score(X_scaled, cluster_labels)\n",
        "inertia = kmeans_model.inertia_\n",
        "\n",
        "print('='*50)\n",
        "print('MÉTRICAS DE CALIDAD DEL CLUSTERING')\n",
        "print('='*50)\n",
        "print(f'\\nSILHOUETTE SCORE: {silhouette:.4f}')\n",
        "print(f'  → Rango: [-1, 1] | Mejor: 1')\n",
        "print(f'  → {silhouette:.4f} indica separación {'buena' if silhouette > 0.5 else 'moderada' if silhouette > 0.3 else 'pobre'} entre clusters')\n",
        "\n",
        "print(f'\\nDAVIES-BOULDIN INDEX: {davies_bouldin:.4f}')\n",
        "print(f'  → Rango: [0, ∞] | Mejor: 0')\n",
        "print(f'  → Mide la similitud promedio entre cada cluster y su más similar')\n",
        "\n",
        "print(f'\\nCALINSKI-HARABASZ INDEX: {calinski_harabasz:.4f}')\n",
        "print(f'  → Mayor es mejor')\n",
        "print(f'  → Ratio entre dispersión entre clusters y dentro de clusters')\n",
        "\n",
        "print(f'\\nINERTIA (Within-cluster sum of squares): {inertia:.2f}')\n",
        "print(f'  → Menor es mejor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen de métricas\n",
        "metrics_summary = {\n",
        "    'Métrica': ['Silhouette Score', 'Davies-Bouldin', 'Calinski-Harabasz', 'Inertia'],\n",
        "    'Valor': [silhouette, davies_bouldin, calinski_harabasz, inertia],\n",
        "    'Interpretación': ['0.62 = Separación moderada', 'Más bajo = mejor', 'Más alto = mejor', 'Suma de distancias']\n",
        "}\n",
        "\n",
        "print('\\nRESUMEN DE MÉTRICAS:')\n",
        "print(pd.DataFrame(metrics_summary).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. GRÁFICAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfica 1: Elbow Method\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Inertia\n",
        "ax1.plot(K_range, inertias, marker='o', linewidth=2, markersize=8, color='#3498db')\n",
        "ax1.axvline(x=3, color='r', linestyle='--', label='k=3 (elegido)', alpha=0.7, linewidth=2)\n",
        "ax1.set_xlabel('Número de Clusters (k)', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Inertia', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Método Elbow', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Silhouette Score\n",
        "ax2.plot(K_range, silhouette_scores, marker='s', linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax2.axvline(x=3, color='r', linestyle='--', label='k=3 (elegido)', alpha=0.7, linewidth=2)\n",
        "ax2.set_xlabel('Número de Clusters (k)', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Silhouette Score por k', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfica 2: Distribución de Clusters\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "bars = ax.bar(cluster_counts.index, cluster_counts.values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{int(height):,}\\n({height/len(cluster_labels)*100:.1f}%)',\n",
        "            ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Número de Clientes', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Distribución de Clusters', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks([0, 1, 2])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfica 3: Churn Rate por Cluster\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "churn_rates = []\n",
        "for cluster in range(3):\n",
        "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster]\n",
        "    churn_rate = (cluster_data['Churn'].sum() / len(cluster_data)) * 100\n",
        "    churn_rates.append(churn_rate)\n",
        "\n",
        "bars = ax.bar(range(3), churn_rates, color=['#2ecc71', '#3498db', '#e74c3c'], alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{height:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "ax.set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Tasa de Churn (%)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Tasa de Churn por Cluster', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks([0, 1, 2])\n",
        "ax.set_ylim(0, 100)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfica 4: Métricas de Calidad\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "metrics_names = ['Silhouette\\n(max 1)', 'Calinski-H\\n(normalized)', 'Davies-B\\n(inverted)']\n",
        "# Normalizar para visualización\n",
        "metrics_values = [\n",
        "    silhouette,\n",
        "    calinski_harabasz / 100,  # normalizar\n",
        "    1 / (1 + davies_bouldin)  # invertir (menor es mejor)\n",
        "]\n",
        "\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "bars = ax.bar(metrics_names, metrics_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for bar, value in zip(bars, metrics_values):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Métricas de Calidad del Clustering', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim(0, 1.2)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfica 5: Características por Cluster (heatmap)\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Seleccionar features importantes\n",
        "important_features = ['MonthlyCharges', 'TotalCharges', 'tenure', 'Churn', 'Contract', 'InternetService']\n",
        "cluster_profiles_subset = df_clustered.groupby('Cluster')[important_features].mean()\n",
        "\n",
        "# Normalizar para mejor visualización\n",
        "cluster_profiles_norm = (cluster_profiles_subset - cluster_profiles_subset.min()) / (cluster_profiles_subset.max() - cluster_profiles_subset.min())\n",
        "\n",
        "sns.heatmap(cluster_profiles_norm.T, annot=True, fmt='.2f', cmap='YlOrRd', cbar_kws={'label': 'Normalized Value'}, ax=ax)\n",
        "ax.set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Features', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Perfiles de Clusters (Features Normalizadas)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar modelo\n",
        "import joblib\n",
        "\n",
        "joblib.dump(kmeans_model, '../public/models/kmeans.pkl')\n",
        "joblib.dump(scaler, '../public/models/kmeans_scaler.pkl')\n",
        "\n",
        "print('Modelo K-Means guardado!')\n",
        "print(f'- Modelo: ../public/models/kmeans.pkl')\n",
        "print(f'- Scaler: ../public/models/kmeans_scaler.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
